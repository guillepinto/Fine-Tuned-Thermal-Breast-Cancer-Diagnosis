{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install torchmetrics\n",
    "! pip install wandb -Uq\n",
    "! pip install timm\n",
    "! pip install onnxruntime-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clone repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/guillepinto/Fine-Tuned-Thermal-Breast-Cancer-Diagnosis.git\n",
    "%cd Fine-Tuned-Thermal-Breast-Cancer-Diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initial setup to connect to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload() # upload your key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ~/kaggle\n",
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset loading\n",
    "\n",
    "Someone uploaded the dataset to kaggle, so we'll take advantage of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! kaggle datasets download -d asdeepak/thermal-images-for-breast-cancer-diagnosis-dmrir\n",
    "! unzip thermal-images-for-breast-cancer-diagnosis-dmrir.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execfile('make_dataset.py')\n",
    "execfile('test.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n de inferencia ONNX\n",
    "def onnx_inference(onnx_path, test_dataset):\n",
    "    session = onnxruntime.InferenceSession(onnx_path, providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for img, label in test_dataset:\n",
    "        ort_inputs = {input_name: img[np.newaxis, ...].astype(np.float32)}\n",
    "        ort_outputs = session.run(None, ort_inputs)\n",
    "        pred = ort_outputs[0]\n",
    "        all_preds.append(pred[0][0])\n",
    "        all_labels.append(label)\n",
    "\n",
    "    return np.array(all_preds), np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, onnx_path in enumerate(onnx_models, 1):\n",
    "        print(f\"Evaluando modelo del fold {fold}\")\n",
    "        test_dataset = get_data(fold=fold, n_channels=1)\n",
    "        preds, labels = onnx_inference(onnx_path, test_dataset)\n",
    "        accuracy, f1, recall, precision = calculate_metrics(preds, labels)\n",
    "        print(f\"Accuracy: {accuracy:.3f}, F1: {f1:.3f}, Recall: {recall:.3f}, Precision: {precision:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
